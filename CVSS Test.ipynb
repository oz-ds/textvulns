{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of CVSS Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnerability descriptions: 32963\n",
      "Vulnerable product names:9176\n",
      "data: 32963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import vulns_common\n",
    "\n",
    "vulns_common.download_nvd_vulns_json()\n",
    "nvd_vulns = vulns_common.load_nvd_vulns_json('data/nvdcve-1.0*.json')\n",
    "print('Vulnerability descriptions: ' + str(len(nvd_vulns)))\n",
    "cpe_names = vulns_common.compile_cpe_names(nvd_vulns)\n",
    "print('Vulnerable product names:'+str(len(cpe_names)))\n",
    "data = shuffle(nvd_vulns)#, n_samples=1000)\n",
    "print('data: ' + str(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CVE-2019-11816',\n",
       " 'Incorrect access control in the WebUI in OPNsense before version 19.1.8, and pfsense before 2.4.4-p3 allows remote authenticated users to escalate privileges to administrator via a specially crafted request.',\n",
       " 'CWE-284',\n",
       " 'AV:N/AC:L/Au:S/C:P/I:P/A:P',\n",
       " 6.5,\n",
       " 'CVSS:3.0/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H',\n",
       " 7.2,\n",
       " ['netgate', 'pfsense']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification distribution CVSS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cvss2_metric_counts(data_):\n",
    "    cvss2_metrics = ['AV:L/','AV:A/','AV:N/',\n",
    "                     'AC:L/','AC:M/','AC:H/',\n",
    "                     'Au:N/','Au:S/','Au:M/',\n",
    "                     'C:N/','C:P/','C:C/',\n",
    "                     'I:N/','I:P/','I:C/',\n",
    "                     '/A:N','/A:P','/A:C']\n",
    "    metric_counts = dict()\n",
    "    for m in cvss2_metrics:\n",
    "        metric_counts[m] = 0\n",
    "\n",
    "    for d in data_:\n",
    "        for m in cvss2_metrics:\n",
    "            if m in d[3]:\n",
    "                metric_counts[m] = metric_counts[m] + 1\n",
    "    return metric_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AV:L/': 4147,\n",
       " 'AV:A/': 631,\n",
       " 'AV:N/': 26634,\n",
       " 'AC:L/': 18153,\n",
       " 'AC:M/': 12754,\n",
       " 'AC:H/': 505,\n",
       " 'Au:N/': 24929,\n",
       " 'Au:S/': 6481,\n",
       " 'Au:M/': 2,\n",
       " 'C:N/': 10589,\n",
       " 'C:P/': 16309,\n",
       " 'C:C/': 4514,\n",
       " 'I:N/': 10310,\n",
       " 'I:P/': 16680,\n",
       " 'I:C/': 4422,\n",
       " '/A:N': 13124,\n",
       " '/A:P': 12730,\n",
       " '/A:C': 5558}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_cvss2_metric_counts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification distribution CVSS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cvss3_metric_counts(data_):\n",
    "    cvss3_metrics = ['AV:L/','AV:A/','AV:N/','AV:P/',\n",
    "                     'AC:L/','AC:H/',\n",
    "                     'PR:N/','PR:L/','PR:H/',\n",
    "                     'UI:N/','UI:R/',\n",
    "                     'S:U/','S:C/',\n",
    "                     '/C:N/','/C:L/','/C:H/',\n",
    "                     '/I:N/','/I:L/','/I:H/',\n",
    "                     '/A:N','/A:L','/A:H']\n",
    "    metric_counts = dict()\n",
    "    for m in cvss3_metrics:\n",
    "        metric_counts[m] = 0\n",
    "\n",
    "    for d in data_:\n",
    "        for m in cvss3_metrics:\n",
    "            if m in d[5]:\n",
    "                metric_counts[m] = metric_counts[m] + 1\n",
    "                \n",
    "    return metric_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AV:L/': 5268,\n",
       " 'AV:A/': 613,\n",
       " 'AV:N/': 21833,\n",
       " 'AV:P/': 291,\n",
       " 'AC:L/': 25704,\n",
       " 'AC:H/': 2301,\n",
       " 'PR:N/': 18875,\n",
       " 'PR:L/': 7453,\n",
       " 'PR:H/': 1677,\n",
       " 'UI:N/': 17845,\n",
       " 'UI:R/': 10160,\n",
       " 'S:U/': 23171,\n",
       " 'S:C/': 4834,\n",
       " '/C:N/': 5985,\n",
       " '/C:L/': 5419,\n",
       " '/C:H/': 16601,\n",
       " '/I:N/': 8431,\n",
       " '/I:L/': 4858,\n",
       " '/I:H/': 14716,\n",
       " '/A:N': 11158,\n",
       " '/A:L': 580,\n",
       " '/A:H': 16267}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_cvss3_metric_counts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification with classifiers suggested by https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVSS2 scoring test. See 'results' structure after run.\n",
      "...... ...... ...... ...... ...... ...... ...... ...... ...... ...... done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction import text \n",
    "from cvsslib import cvss2, cvss3, calculate_vector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        self.stemmer = SnowballStemmer(\"english\")\n",
    "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (analyzer(' '.join([self.stemmer.stem(word) for word in doc.split(' ')])))\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        self.stemmer = SnowballStemmer(\"english\")\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (analyzer(' '.join([self.stemmer.stem(word) for word in doc.split(' ')])))\n",
    "\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        self.stemmer = WordNetLemmatizer()\n",
    "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (analyzer(' '.join([self.stemmer.lemmatize(word) for word in doc.split(' ')])))    \n",
    "\n",
    "class LemmaTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        self.stemmer = WordNetLemmatizer()\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (analyzer(' '.join([self.stemmer.lemmatize(word) for word in doc.split(' ')])))    \n",
    "\n",
    "unwanted_words = ['issue','defect','bug','fault','flaw','mistake','error','version','system','because','before','disputed']\n",
    "stop_words = text.ENGLISH_STOP_WORDS#.union(cpe_names)\n",
    "stop_words = stop_words.union(unwanted_words)\n",
    "\n",
    "l = True\n",
    "ngram_s = 1\n",
    "ngram_e = 3\n",
    "df = 1\n",
    "t = r'(?u)\\b\\w*[a-zA-Z]{3,}\\w*\\b'\n",
    "\n",
    "vectorizers = [\n",
    "    #CountVectorizer(stop_words=stop_words, lowercase=l, ngram_range=(ngram_s, ngram_e), min_df=df, token_pattern=t),\n",
    "    #StemmedCountVectorizer(stop_words=stop_words, lowercase=l, ngram_range=(ngram_s, ngram_e), min_df=df, token_pattern=t),\n",
    "    TfidfVectorizer(stop_words=stop_words, lowercase=l, ngram_range=(ngram_s, ngram_e), min_df=df, token_pattern=t),\n",
    "    #StemmedTfidfVectorizer(stop_words=stop_words, lowercase=l, ngram_range=(ngram_s, ngram_e), min_df=df, token_pattern=t),\n",
    "    #LemmaTfidfVectorizer(stop_words=stop_words, lowercase=l, ngram_range=(ngram_s, ngram_e), min_df=df, token_pattern=t),\n",
    "    #LemmaCountVectorizer(stop_words=stop_words, lowercase=l, ngram_range=(ngram_s, ngram_e), min_df=df, token_pattern=t),\n",
    "              ]\n",
    "\n",
    "classifiers = [\n",
    "               #MultinomialNB(),\n",
    "               #SGDClassifier(tol=1e-3, shuffle=True),\n",
    "               LinearSVC(),\n",
    "               #KNeighborsClassifier()\n",
    "              ]\n",
    "\n",
    "#CVSS2\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop(df[df[3] == ''].index)\n",
    "df = df.drop(df[df[4] == ''].index)\n",
    "df = df.drop([0,2,5,6,7], axis=1)\n",
    "df = df.rename(index=str, columns={1: 'text', 3: 'vector'})\n",
    "\n",
    "print('CVSS2 scoring test. See \\'results\\' structure after run.')\n",
    "results = []\n",
    "for nfold in range(10):\n",
    "    X_train, X_test, train_cvss_vectors, y_test = train_test_split(df['text'], df['vector'])\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "            pipe = Pipeline([('vect', vectorizer), ('cls', classifier)])#('scale', StandardScaler(with_mean=False)),\n",
    "            t = time.time()\n",
    "            #fit and predict\n",
    "            pred = pd.DataFrame(X_test)\n",
    "            for i in range(6):# 6 classes on cvss2 metrics\n",
    "                vector = train_cvss_vectors.str.split('/').str.get(i)\n",
    "                pipe.fit(X_train, vector)\n",
    "                predicted = pipe.predict(X_test)\n",
    "                pred[i] = predicted\n",
    "                print('.', end='')\n",
    "\n",
    "            #calculate cvss2 scores\n",
    "            for index, value in pred.iterrows():\n",
    "                vector =''\n",
    "                for i in range(6):\n",
    "                    vector = vector + value[i] + '/'\n",
    "                vector = vector[0:len(vector)-1]\n",
    "                score = calculate_vector(vector, cvss2)\n",
    "                pred.at[index, 'score'] = score[0]\n",
    "                pred.at[index, 'truth'] = df.loc[index][4]\n",
    "\n",
    "            pred.at[pred['score'] < 3.9, 'severity'] = 'low'\n",
    "            pred.at[pred['score'] >= 4.0, 'severity'] = 'medium'\n",
    "            pred.at[pred['score'] >= 7.0, 'severity'] = 'high'\n",
    "            pred.at[pred['score'] >= 9.0, 'severity'] = 'critical'\n",
    "\n",
    "            pred.at[pred['truth'] < 3.9, 'severity_truth'] = 'low'\n",
    "            pred.at[pred['truth'] >= 4.0, 'severity_truth'] = 'medium'\n",
    "            pred.at[pred['truth'] >= 7.0, 'severity_truth'] = 'high'\n",
    "            pred.at[pred['truth'] >= 9.0, 'severity_truth'] = 'critical'\n",
    "\n",
    "            score = f1_score(y_true=pred['severity_truth'], y_pred=pred['severity'], average='micro')\n",
    "            id = str(classifier)[0:str(classifier).find('(')] + ' ' + str(vectorizer)[0:str(vectorizer).find('(')]\n",
    "            results.append([id, score, round(time.time() - t, 1)])\n",
    "            print(' ', end='')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LinearSVC TfidfVectorizer', 0.8436266395008277, 59.5],\n",
       " ['LinearSVC TfidfVectorizer', 0.8408251623583344, 61.4],\n",
       " ['LinearSVC TfidfVectorizer', 0.8353495479434611, 54.4],\n",
       " ['LinearSVC TfidfVectorizer', 0.8406978224882211, 53.6],\n",
       " ['LinearSVC TfidfVectorizer', 0.8395517636572011, 53.4],\n",
       " ['LinearSVC TfidfVectorizer', 0.8446453584617345, 53.5],\n",
       " ['LinearSVC TfidfVectorizer', 0.8405704826181077, 53.7],\n",
       " ['LinearSVC TfidfVectorizer', 0.8413345218387878, 56.1],\n",
       " ['LinearSVC TfidfVectorizer', 0.8406978224882211, 60.1],\n",
       " ['LinearSVC TfidfVectorizer', 0.8399337832675411, 58.8]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVSS3 scoring test. See 'results' structure after run.\n",
      "........ ........ ........ ........ ........ ........ ........ ........ ........ ........ done\n"
     ]
    }
   ],
   "source": [
    "#CVSS3\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop(df[df[5] == ''].index)\n",
    "df = df.drop(df[df[6] == ''].index)\n",
    "df = df.drop([0,2,3,4,7], axis=1)\n",
    "df = df.rename(index=str, columns={1: 'text', 5: 'vector'})\n",
    "\n",
    "print('CVSS3 scoring test. See \\'results\\' structure after run.')\n",
    "results = []\n",
    "for nfold in range(10):\n",
    "    X_train, X_test, train_cvss_vectors, y_test = train_test_split(df['text'], df['vector'])\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "            pipe = Pipeline([('vect', vectorizer), ('cls', classifier)])\n",
    "            t = time.time()\n",
    "            #fit and predict\n",
    "            pred = pd.DataFrame(X_test)\n",
    "            for i in range(8):# 8 classes on cvss3 metrics\n",
    "                vector = train_cvss_vectors.str.split('/').str.get(i+1)\n",
    "                pipe.fit(X_train, vector)\n",
    "                predicted = pipe.predict(X_test)\n",
    "                pred[i] = predicted\n",
    "                print('.', end='')\n",
    "\n",
    "            #calculate cvss3 scores\n",
    "            for index, value in pred.iterrows():\n",
    "                vector =''\n",
    "                for i in range(8):\n",
    "                    vector = vector + value[i] + '/'\n",
    "                vector = vector[0:len(vector)-1]\n",
    "                score = calculate_vector(vector, cvss3)\n",
    "                pred.at[index, 'score'] = score[0]\n",
    "                pred.at[index, 'truth'] = df.loc[index][6]\n",
    "\n",
    "            pred.at[pred['score'] < 3.9, 'severity'] = 'low'\n",
    "            pred.at[pred['score'] >= 4.0, 'severity'] = 'medium'\n",
    "            pred.at[pred['score'] >= 7.0, 'severity'] = 'high'\n",
    "            pred.at[pred['score'] >= 9.0, 'severity'] = 'critical'\n",
    "            pred['severity'] = pred['severity'].values.astype(str)\n",
    "\n",
    "            pred.at[pred['truth'] < 3.9, 'severity_truth'] = 'low'\n",
    "            pred.at[pred['truth'] >= 4.0, 'severity_truth'] = 'medium'\n",
    "            pred.at[pred['truth'] >= 7.0, 'severity_truth'] = 'high'\n",
    "            pred.at[pred['truth'] >= 9.0, 'severity_truth'] = 'critical'\n",
    "            pred['severity_truth'] = pred['severity_truth'].values.astype(str)\n",
    "\n",
    "            score = f1_score(y_true=pred['severity_truth'], y_pred=pred['severity'], average='micro')\n",
    "            id = str(classifier)[0:str(classifier).find('(')] + ' ' + str(vectorizer)[0:str(vectorizer).find('(')]\n",
    "            results.append([id, score, round(time.time() - t, 1)])\n",
    "            results.append(score)\n",
    "            print(' ', end='')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LinearSVC TfidfVectorizer', 0.8174807197943444, 66.1],\n",
       " 0.8174807197943444,\n",
       " ['LinearSVC TfidfVectorizer', 0.8053413310482719, 66.1],\n",
       " 0.8053413310482719,\n",
       " ['LinearSVC TfidfVectorizer', 0.8154812910596972, 65.5],\n",
       " 0.8154812910596972,\n",
       " ['LinearSVC TfidfVectorizer', 0.8116252499285919, 66.1],\n",
       " 0.8116252499285919,\n",
       " ['LinearSVC TfidfVectorizer', 0.8164810054270208, 65.9],\n",
       " 0.8164810054270208,\n",
       " ['LinearSVC TfidfVectorizer', 0.8157669237360754, 65.0],\n",
       " 0.8157669237360754,\n",
       " ['LinearSVC TfidfVectorizer', 0.8106255355612683, 64.2],\n",
       " 0.8106255355612683,\n",
       " ['LinearSVC TfidfVectorizer', 0.8111968009140245, 64.8],\n",
       " 0.8111968009140245,\n",
       " ['LinearSVC TfidfVectorizer', 0.8116252499285919, 64.5],\n",
       " 0.8116252499285919,\n",
       " ['LinearSVC TfidfVectorizer', 0.8094830048557555, 64.8],\n",
       " 0.8094830048557555]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS2 resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31412\n",
      "31412\n",
      "31410\n",
      "31412\n",
      "31412\n",
      "31412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "def cvss2_sample(data_, min_samples, max_samples):\n",
    "    cvss2_metrics = [['AV:L/','AV:A/','AV:N/'],\n",
    "                     ['AC:L/','AC:M/','AC:H/'],\n",
    "                     ['Au:N/','Au:S/','Au:M/'],\n",
    "                     ['C:N/','C:P/','C:C/'],\n",
    "                     ['I:N/','I:P/','I:C/'],\n",
    "                     ['/A:N','/A:P','/A:C']]\n",
    "\n",
    "    metric_counts = update_cvss2_metric_counts(data_)\n",
    "    all_texts = []\n",
    "\n",
    "    df = pd.DataFrame(data_)\n",
    "    df = df.drop([0,2,5,6,7],axis=1)\n",
    "    df = df.drop(df[df[3] == ''].index)\n",
    "    df = df.drop(df[df[4] == ''].index)\n",
    "    df = df.rename(index=str, columns={1: 'text', 3: 'vector'})\n",
    "\n",
    "    for i in range(6):\n",
    "        texts = pd.DataFrame()\n",
    "        for m in cvss2_metrics[i]:\n",
    "            if metric_counts[m] > max_samples:\n",
    "                resampled = resample(df[df['vector'].str.contains(m)], replace=False, n_samples=max_samples)\n",
    "                resampled['label'] = m\n",
    "                texts = pd.concat([texts, resampled], sort=False)\n",
    "                #print(m+' resampled to '+str(len(resampled)))\n",
    "            elif metric_counts[m] >= min_samples:\n",
    "                resampled = pd.DataFrame(df[df['vector'].str.contains(m)])\n",
    "                resampled['label'] = m\n",
    "                texts = pd.concat([texts, resampled], sort=False)\n",
    "        texts = texts.drop(['vector'],axis=1)\n",
    "        all_texts.append(texts)\n",
    "        \n",
    "    return all_texts\n",
    "\n",
    "cvss2_texts = cvss2_sample(data, 10, 100000)\n",
    "\n",
    "for t in cvss2_texts:\n",
    "    print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS3 resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28005\n",
      "28005\n",
      "28005\n",
      "28005\n",
      "28005\n",
      "28005\n",
      "28005\n",
      "28005\n"
     ]
    }
   ],
   "source": [
    "def cvss3_sample(data_, min_samples, max_samples):\n",
    "    cvss3_metrics = [['AV:L/','AV:A/','AV:N/','AV:P/'],\n",
    "                     ['AC:L/','AC:H/'],\n",
    "                     ['PR:N/','PR:L/','PR:H/'],\n",
    "                     ['UI:N/','UI:R/'],\n",
    "                     ['S:U/','S:C/'],\n",
    "                     ['/C:N/','/C:L/','/C:H/'],\n",
    "                     ['/I:N/','/I:L/','/I:H/'],\n",
    "                     ['/A:N','/A:L','/A:H']]\n",
    "\n",
    "    metric_counts = update_cvss3_metric_counts(data_)\n",
    "    all_texts = []\n",
    "\n",
    "    df = pd.DataFrame(data_)\n",
    "    df = df.drop([0,2,4,3,7],axis=1)\n",
    "    df = df.drop(df[df[5] == ''].index)\n",
    "    df = df.drop(df[df[6] == ''].index)\n",
    "    df = df.rename(index=str, columns={1: 'text', 5: 'vector'})\n",
    "\n",
    "    for i in range(8):\n",
    "        texts = pd.DataFrame()\n",
    "        for m in cvss3_metrics[i]:\n",
    "            if metric_counts[m] > max_samples:\n",
    "                resampled = resample(df[df['vector'].str.contains(m)], replace=False, n_samples=max_samples)\n",
    "                resampled['label'] = m\n",
    "                texts = pd.concat([texts, resampled], sort=False)\n",
    "                #print(m+' resampled to '+str(len(resampled)))\n",
    "            elif metric_counts[m] >= min_samples:\n",
    "                resampled = pd.DataFrame(df[df['vector'].str.contains(m)])\n",
    "                resampled['label'] = m\n",
    "                texts = pd.concat([texts, resampled], sort=False)\n",
    "        texts = texts.drop(['vector'],axis=1)\n",
    "        all_texts.append(texts)\n",
    "    \n",
    "    return all_texts\n",
    "\n",
    "cvss3_texts = cvss3_sample(data, 10, 100000)\n",
    "\n",
    "for t in cvss3_texts:\n",
    "    print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors shape:(28005, 471601)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'discovered': 127233,\n",
       " 'sox': 388549,\n",
       " 'xmalloc': 466361,\n",
       " 'integer': 216692,\n",
       " 'overflow': 289171,\n",
       " 'result': 352839,\n",
       " 'multiplication': 270684,\n",
       " 'fed': 162192,\n",
       " 'lsx_valloc': 248926,\n",
       " 'macro': 249967,\n",
       " 'wraps': 464098,\n",
       " 'malloc': 252972,\n",
       " 'buffer': 55306,\n",
       " 'allocated': 19752,\n",
       " 'smaller': 385095,\n",
       " 'expected': 155811,\n",
       " 'leading': 234943,\n",
       " 'heap': 191567,\n",
       " 'based': 47667,\n",
       " 'channels_start': 67909,\n",
       " 'remix': 344462,\n",
       " 'discovered sox': 129164,\n",
       " 'sox xmalloc': 388560,\n",
       " 'xmalloc integer': 466362,\n",
       " 'integer overflow': 216716,\n",
       " 'overflow result': 290243,\n",
       " 'result multiplication': 353322,\n",
       " 'multiplication fed': 270689,\n",
       " 'fed lsx_valloc': 162195,\n",
       " 'lsx_valloc macro': 248927,\n",
       " 'macro wraps': 250020,\n",
       " 'wraps malloc': 464099,\n",
       " 'malloc buffer': 252975,\n",
       " 'buffer allocated': 55328,\n",
       " 'allocated smaller': 19831,\n",
       " 'smaller expected': 385101,\n",
       " 'expected leading': 155847,\n",
       " 'leading heap': 235115,\n",
       " 'heap based': 191583,\n",
       " 'based buffer': 47746,\n",
       " 'buffer overflow': 55551,\n",
       " 'overflow channels_start': 289365,\n",
       " 'channels_start remix': 67910,\n",
       " 'discovered sox xmalloc': 129167,\n",
       " 'sox xmalloc integer': 388561,\n",
       " 'xmalloc integer overflow': 466363,\n",
       " 'integer overflow result': 216808,\n",
       " 'overflow result multiplication': 290246,\n",
       " 'result multiplication fed': 353323,\n",
       " 'multiplication fed lsx_valloc': 270690,\n",
       " 'fed lsx_valloc macro': 162196,\n",
       " 'lsx_valloc macro wraps': 248928,\n",
       " 'macro wraps malloc': 250021,\n",
       " 'wraps malloc buffer': 464100,\n",
       " 'malloc buffer allocated': 252976,\n",
       " 'buffer allocated smaller': 55333,\n",
       " 'allocated smaller expected': 19832,\n",
       " 'smaller expected leading': 385102,\n",
       " 'expected leading heap': 155848,\n",
       " 'leading heap based': 235116,\n",
       " 'heap based buffer': 191585,\n",
       " 'based buffer overflow': 47751,\n",
       " 'buffer overflow channels_start': 55611,\n",
       " 'overflow channels_start remix': 289366,\n",
       " 'input': 212725,\n",
       " 'validation': 438691,\n",
       " 'exists': 153518,\n",
       " 'ttembed': 416771,\n",
       " 'crafted': 99888,\n",
       " 'file': 163493,\n",
       " 'attacker': 36577,\n",
       " 'able': 1867,\n",
       " 'trigger': 415345,\n",
       " 'denial': 117241,\n",
       " 'service': 374361,\n",
       " 'condition': 84890,\n",
       " 'trusting': 416574,\n",
       " 'controlled': 95440,\n",
       " 'values': 440383,\n",
       " 'input validation': 213477,\n",
       " 'validation exists': 438988,\n",
       " 'exists ttembed': 155268,\n",
       " 'ttembed crafted': 416772,\n",
       " 'crafted input': 100612,\n",
       " 'input file': 213013,\n",
       " 'file attacker': 163697,\n",
       " 'attacker able': 36592,\n",
       " 'able trigger': 2314,\n",
       " 'trigger denial': 415438,\n",
       " 'denial service': 117246,\n",
       " 'service condition': 374801,\n",
       " 'condition ttembed': 85439,\n",
       " 'ttembed trusting': 416776,\n",
       " 'trusting attacker': 416575,\n",
       " 'attacker controlled': 37423,\n",
       " 'controlled values': 95613,\n",
       " 'input validation exists': 213535,\n",
       " 'validation exists ttembed': 438989,\n",
       " 'exists ttembed crafted': 155269,\n",
       " 'ttembed crafted input': 416773,\n",
       " 'crafted input file': 100618,\n",
       " 'input file attacker': 213015,\n",
       " 'file attacker able': 163698,\n",
       " 'attacker able trigger': 36666,\n",
       " 'able trigger denial': 2316,\n",
       " 'trigger denial service': 415439,\n",
       " 'denial service condition': 117299,\n",
       " 'service condition ttembed': 374842,\n",
       " 'condition ttembed trusting': 85440,\n",
       " 'ttembed trusting attacker': 416777,\n",
       " 'trusting attacker controlled': 416576,\n",
       " 'attacker controlled values': 37455,\n",
       " 'vulnerability': 448907,\n",
       " 'cisco': 70809,\n",
       " 'roomos': 356642,\n",
       " 'software': 386860,\n",
       " 'allow': 20052,\n",
       " 'authenticated': 42450,\n",
       " 'local': 244069,\n",
       " 'write': 464186,\n",
       " 'files': 167038,\n",
       " 'underlying': 420145,\n",
       " 'filesystem': 168642,\n",
       " 'root': 356657,\n",
       " 'privileges': 322750,\n",
       " 'insufficient': 216274,\n",
       " 'permission': 304119,\n",
       " 'restrictions': 352583,\n",
       " 'specific': 389408,\n",
       " 'process': 324108,\n",
       " 'exploit': 156166,\n",
       " 'logging': 246326,\n",
       " 'affected': 15329,\n",
       " 'device': 120548,\n",
       " 'remote': 344463,\n",
       " 'support': 401326,\n",
       " 'credentials': 103885,\n",
       " 'initiating': 210831,\n",
       " 'sending': 369147,\n",
       " 'data': 109899,\n",
       " 'successful': 399908,\n",
       " 'vulnerability cisco': 449736,\n",
       " 'cisco roomos': 71604,\n",
       " 'roomos software': 356643,\n",
       " 'software allow': 386875,\n",
       " 'allow authenticated': 20346,\n",
       " 'authenticated local': 42704,\n",
       " 'local attacker': 244156,\n",
       " 'attacker write': 39704,\n",
       " 'write files': 464416,\n",
       " 'files underlying': 168445,\n",
       " 'underlying filesystem': 420174,\n",
       " 'filesystem root': 168758,\n",
       " 'root privileges': 357016,\n",
       " 'privileges vulnerability': 323623,\n",
       " 'vulnerability insufficient': 451772,\n",
       " 'insufficient permission': 216440,\n",
       " 'permission restrictions': 304386,\n",
       " 'restrictions specific': 352789,\n",
       " 'specific process': 389849,\n",
       " 'process attacker': 324174,\n",
       " 'attacker exploit': 37879,\n",
       " 'exploit vulnerability': 156530,\n",
       " 'vulnerability logging': 452264,\n",
       " 'logging affected': 246334,\n",
       " 'affected device': 15548,\n",
       " 'device remote': 121668,\n",
       " 'remote support': 345185,\n",
       " 'support credentials': 401373,\n",
       " 'credentials initiating': 104180,\n",
       " 'initiating specific': 210842,\n",
       " 'process device': 324341,\n",
       " 'device sending': 121785,\n",
       " 'sending crafted': 369207,\n",
       " 'crafted data': 100222,\n",
       " 'data process': 111218,\n",
       " 'process successful': 324779,\n",
       " 'successful exploit': 399942,\n",
       " 'exploit allow': 156171,\n",
       " 'allow attacker': 20127,\n",
       " 'underlying file': 420171,\n",
       " 'file root': 165695,\n",
       " 'vulnerability cisco roomos': 449767,\n",
       " 'cisco roomos software': 71605,\n",
       " 'roomos software allow': 356644,\n",
       " 'software allow authenticated': 386878,\n",
       " 'allow authenticated local': 20357,\n",
       " 'authenticated local attacker': 42705,\n",
       " 'local attacker write': 244229,\n",
       " 'attacker write files': 39714,\n",
       " 'write files underlying': 464429,\n",
       " 'files underlying filesystem': 168447,\n",
       " 'underlying filesystem root': 420177,\n",
       " 'filesystem root privileges': 168759,\n",
       " 'root privileges vulnerability': 357055,\n",
       " 'privileges vulnerability insufficient': 323637,\n",
       " 'vulnerability insufficient permission': 451796,\n",
       " 'insufficient permission restrictions': 216443,\n",
       " 'permission restrictions specific': 304387,\n",
       " 'restrictions specific process': 352790,\n",
       " 'specific process attacker': 389850,\n",
       " 'process attacker exploit': 324178,\n",
       " 'attacker exploit vulnerability': 37923,\n",
       " 'exploit vulnerability logging': 156632,\n",
       " 'vulnerability logging affected': 452265,\n",
       " 'logging affected device': 246335,\n",
       " 'affected device remote': 15647,\n",
       " 'device remote support': 121670,\n",
       " 'remote support credentials': 345187,\n",
       " 'support credentials initiating': 401375,\n",
       " 'credentials initiating specific': 104181,\n",
       " 'initiating specific process': 210843,\n",
       " 'specific process device': 389851,\n",
       " 'process device sending': 324342,\n",
       " 'device sending crafted': 121786,\n",
       " 'sending crafted data': 369223,\n",
       " 'crafted data process': 100229,\n",
       " 'data process successful': 111221,\n",
       " 'process successful exploit': 324781,\n",
       " 'successful exploit allow': 399943,\n",
       " 'exploit allow attacker': 156172,\n",
       " 'allow attacker write': 20302,\n",
       " 'files underlying file': 168446,\n",
       " 'underlying file root': 420172,\n",
       " 'file root privileges': 165700,\n",
       " 'jasper': 223812,\n",
       " 'allows': 21757,\n",
       " 'reachable': 336307,\n",
       " 'assertion': 34260,\n",
       " 'function': 177377,\n",
       " 'jpc_firstone': 227033,\n",
       " 'libjasper': 238659,\n",
       " 'jpc': 227015,\n",
       " 'jpc_math': 227036,\n",
       " 'jasper allows': 223815,\n",
       " 'allows denial': 22310,\n",
       " 'service reachable': 375910,\n",
       " 'reachable assertion': 336317,\n",
       " 'assertion function': 34303,\n",
       " 'function jpc_firstone': 178316,\n",
       " 'jpc_firstone libjasper': 227034,\n",
       " 'libjasper jpc': 238665,\n",
       " 'jpc jpc_math': 227021,\n",
       " 'jasper allows denial': 223816,\n",
       " 'allows denial service': 22311,\n",
       " 'denial service reachable': 117480,\n",
       " 'service reachable assertion': 375911,\n",
       " 'reachable assertion function': 336321,\n",
       " 'assertion function jpc_firstone': 34305,\n",
       " 'function jpc_firstone libjasper': 178317,\n",
       " 'jpc_firstone libjasper jpc': 227035,\n",
       " 'libjasper jpc jpc_math': 238668,\n",
       " 'android': 24226,\n",
       " 'kernel': 228869,\n",
       " 'mnh': 265205,\n",
       " 'driver': 135308,\n",
       " 'possible': 315689,\n",
       " 'bounds': 53219,\n",
       " 'improper': 204632,\n",
       " 'lead': 234399,\n",
       " 'escalation': 147205,\n",
       " 'privilege': 322019,\n",
       " 'execution': 151802,\n",
       " 'needed': 272829,\n",
       " 'user': 429591,\n",
       " 'interaction': 217949,\n",
       " 'exploitation': 157185,\n",
       " 'android kernel': 24406,\n",
       " 'kernel mnh': 229290,\n",
       " 'mnh driver': 265206,\n",
       " 'driver possible': 135566,\n",
       " 'possible bounds': 315772,\n",
       " 'bounds write': 53482,\n",
       " 'write improper': 464470,\n",
       " 'improper input': 204854,\n",
       " 'validation lead': 439159,\n",
       " 'lead escalation': 234583,\n",
       " 'escalation privilege': 147386,\n",
       " 'privilege execution': 322214,\n",
       " 'execution privileges': 152477,\n",
       " 'privileges needed': 323288,\n",
       " 'needed user': 272863,\n",
       " 'user interaction': 431419,\n",
       " 'interaction needed': 218013,\n",
       " 'needed exploitation': 272850,\n",
       " 'android kernel mnh': 24410,\n",
       " 'kernel mnh driver': 229291,\n",
       " 'mnh driver possible': 265207,\n",
       " 'driver possible bounds': 135567,\n",
       " 'possible bounds write': 315776,\n",
       " 'bounds write improper': 53509,\n",
       " 'write improper input': 464471,\n",
       " 'improper input validation': 204858,\n",
       " 'input validation lead': 213565,\n",
       " 'validation lead escalation': 439161,\n",
       " 'lead escalation privilege': 234584,\n",
       " 'escalation privilege execution': 147395,\n",
       " 'privilege execution privileges': 322215,\n",
       " 'execution privileges needed': 152480,\n",
       " 'privileges needed user': 323291,\n",
       " 'needed user interaction': 272864,\n",
       " 'user interaction needed': 431430,\n",
       " 'interaction needed exploitation': 218014,\n",
       " 'way': 456521,\n",
       " 'linux': 241876,\n",
       " 'kvm': 232005,\n",
       " 'hypervisor': 197949,\n",
       " 'emulated': 142163,\n",
       " 'instructions': 216222,\n",
       " 'sgdt': 379816,\n",
       " 'sidt': 381573,\n",
       " 'fxsave': 180615,\n",
       " 'fxrstor': 180612,\n",
       " 'did': 123787,\n",
       " 'check': 68483,\n",
       " 'current': 107797,\n",
       " 'cpl': 99167,\n",
       " 'level': 237147,\n",
       " 'emulating': 142172,\n",
       " 'unprivileged': 421889,\n",
       " 'guest': 187201,\n",
       " 'use': 426803,\n",
       " 'potentially': 317223,\n",
       " 'escalate': 147091,\n",
       " 'inside': 214272,\n",
       " 'way linux': 456675,\n",
       " 'linux kernel': 241992,\n",
       " 'kernel kvm': 229218,\n",
       " 'kvm hypervisor': 232014,\n",
       " 'hypervisor emulated': 197967,\n",
       " 'emulated instructions': 142164,\n",
       " 'instructions sgdt': 216243,\n",
       " 'sgdt sidt': 379817,\n",
       " 'sidt fxsave': 381574,\n",
       " 'fxsave fxrstor': 180616,\n",
       " 'fxrstor did': 180613,\n",
       " 'did check': 123801,\n",
       " 'check current': 68620,\n",
       " 'current privilege': 107875,\n",
       " 'privilege cpl': 322089,\n",
       " 'cpl level': 99172,\n",
       " 'level emulating': 237264,\n",
       " 'emulating unprivileged': 142173,\n",
       " 'unprivileged instructions': 421916,\n",
       " 'instructions unprivileged': 216249,\n",
       " 'unprivileged guest': 421913,\n",
       " 'guest user': 187389,\n",
       " 'user process': 432320,\n",
       " 'process use': 324844,\n",
       " 'use potentially': 427767,\n",
       " 'potentially escalate': 317415,\n",
       " 'escalate privileges': 147114,\n",
       " 'privileges inside': 323176,\n",
       " 'inside guest': 214346,\n",
       " 'way linux kernel': 456676,\n",
       " 'linux kernel kvm': 242070,\n",
       " 'kernel kvm hypervisor': 229219,\n",
       " 'kvm hypervisor emulated': 232015,\n",
       " 'hypervisor emulated instructions': 197968,\n",
       " 'emulated instructions sgdt': 142165,\n",
       " 'instructions sgdt sidt': 216244,\n",
       " 'sgdt sidt fxsave': 379818,\n",
       " 'sidt fxsave fxrstor': 381575,\n",
       " 'fxsave fxrstor did': 180617,\n",
       " 'fxrstor did check': 180614,\n",
       " 'did check current': 123803,\n",
       " 'check current privilege': 68622,\n",
       " 'current privilege cpl': 107876,\n",
       " 'privilege cpl level': 322090,\n",
       " 'cpl level emulating': 99173,\n",
       " 'level emulating unprivileged': 237265,\n",
       " 'emulating unprivileged instructions': 142174,\n",
       " 'unprivileged instructions unprivileged': 421917,\n",
       " 'instructions unprivileged guest': 216250,\n",
       " 'unprivileged guest user': 421915,\n",
       " 'guest user process': 187398,\n",
       " 'user process use': 432326,\n",
       " 'process use potentially': 324848,\n",
       " 'use potentially escalate': 427769,\n",
       " 'potentially escalate privileges': 317417,\n",
       " 'escalate privileges inside': 147138,\n",
       " 'privileges inside guest': 323177,\n",
       " 'exacqvision': 149307,\n",
       " 'enterprise': 145231,\n",
       " 'manager': 254098,\n",
       " 'esm': 147858,\n",
       " 'application': 28213,\n",
       " 'unauthorized': 419498,\n",
       " 'achieved': 7696,\n",
       " 'impacts': 202549,\n",
       " 'prior': 320051,\n",
       " 'versions': 442808,\n",
       " 'running': 359504,\n",
       " 'windows': 461000,\n",
       " 'operating': 285611,\n",
       " 'does': 132390,\n",
       " 'impact': 202030,\n",
       " 'server': 371595,\n",
       " 'oss': 288418,\n",
       " 'deployments': 118131,\n",
       " 'permissions': 304474,\n",
       " 'inherited': 210428,\n",
       " 'directory': 125219,\n",
       " 'authorized': 44755,\n",
       " 'users': 433901,\n",
       " 'modify': 266758,\n",
       " 'folders': 172670,\n",
       " 'low': 248574,\n",
       " 'account': 6561,\n",
       " 'located': 244977,\n",
       " 'directories': 125090,\n",
       " 'executable': 150494,\n",
       " 'renamed': 345763,\n",
       " 'replaced': 346310,\n",
       " 'malicious': 251611,\n",
       " 'connect': 88537,\n",
       " 'bad': 46998,\n",
       " 'actor': 9308,\n",
       " 'providing': 331065,\n",
       " 'privileged': 322462,\n",
       " 'restart': 351794,\n",
       " 'affects': 16651,\n",
       " 'exacq': 149304,\n",
       " 'technologies': 406618,\n",
       " 'affect': 15242,\n",
       " 'vulnerability exacqvision': 450466,\n",
       " 'exacqvision enterprise': 149308,\n",
       " 'enterprise manager': 145428,\n",
       " 'manager esm': 254353,\n",
       " 'esm application': 147859,\n",
       " 'application unauthorized': 29509,\n",
       " 'unauthorized privilege': 419717,\n",
       " 'privilege escalation': 322107,\n",
       " 'escalation potentially': 147382,\n",
       " 'potentially achieved': 317238,\n",
       " 'achieved vulnerability': 7727,\n",
       " 'vulnerability impacts': 451507,\n",
       " 'impacts exacqvision': 202565,\n",
       " 'exacqvision esm': 149310,\n",
       " 'esm prior': 147863,\n",
       " 'prior versions': 321521,\n",
       " 'versions esm': 443374,\n",
       " 'esm running': 147867,\n",
       " 'running windows': 360002,\n",
       " 'windows operating': 461487,\n",
       " 'operating does': 285686,\n",
       " 'does impact': 132682,\n",
       " 'impact windows': 202457,\n",
       " 'windows server': 461624,\n",
       " 'server oss': 373064,\n",
       " 'oss linux': 288423,\n",
       " 'linux deployments': 241930,\n",
       " 'deployments permissions': 118150,\n",
       " 'permissions inherited': 304703,\n",
       " 'inherited root': 210440,\n",
       " 'root directory': 356840,\n",
       " 'directory authorized': 125289,\n",
       " 'authorized users': 44833,\n",
       " 'users modify': 434689,\n",
       " 'modify permission': 267001,\n",
       " 'permission esm': 304254,\n",
       " 'esm folders': 147861,\n",
       " 'folders allows': 172687,\n",
       " 'allows low': 22575,\n",
       " 'low privilege': 248621,\n",
       " 'privilege account': 322024,\n",
       " 'account modify': 6977,\n",
       " 'modify files': 266894,\n",
       " 'files located': 167872,\n",
       " 'located directories': 245016,\n",
       " 'directories executable': 125128,\n",
       " 'executable renamed': 150627,\n",
       " 'renamed replaced': 345778,\n",
       " 'replaced malicious': 346325,\n",
       " 'malicious file': 251982,\n",
       " 'file connect': 163929,\n",
       " 'connect bad': 88574,\n",
       " 'bad actor': 46999,\n",
       " 'actor providing': 9344,\n",
       " 'providing level': 331102,\n",
       " 'level privileges': 237348,\n",
       " 'privileges low': 323235,\n",
       " 'low privileged': 248630,\n",
       " 'privileged user': 322674,\n",
       " 'user able': 429602,\n",
       " 'able restart': 2249,\n",
       " 'restart service': 351920,\n",
       " 'service restart': 375993,\n",
       " 'restart trigger': 351947,\n",
       " 'trigger execution': 415475,\n",
       " 'execution malicious': 152319,\n",
       " 'file affects': 163592,\n",
       " 'affects exacq': 16777,\n",
       " 'exacq technologies': 149305,\n",
       " 'technologies exacqvision': 406629,\n",
       " 'versions does': 443262,\n",
       " 'does affect': 132406,\n",
       " 'affect exacq': 15270,\n",
       " 'vulnerability exacqvision enterprise': 450467,\n",
       " 'exacqvision enterprise manager': 149309,\n",
       " 'enterprise manager esm': 145435,\n",
       " 'manager esm application': 254354,\n",
       " 'esm application unauthorized': 147860,\n",
       " 'application unauthorized privilege': 29510,\n",
       " 'unauthorized privilege escalation': 419718,\n",
       " 'privilege escalation potentially': 322186,\n",
       " 'escalation potentially achieved': 147383,\n",
       " 'potentially achieved vulnerability': 317239,\n",
       " 'achieved vulnerability impacts': 7728,\n",
       " 'vulnerability impacts exacqvision': 451510,\n",
       " 'impacts exacqvision esm': 202566,\n",
       " 'exacqvision esm prior': 149311,\n",
       " 'esm prior versions': 147866,\n",
       " 'prior versions esm': 321530,\n",
       " 'versions esm running': 443375,\n",
       " 'esm running windows': 147868,\n",
       " 'running windows operating': 360007,\n",
       " 'windows operating does': 461493,\n",
       " 'operating does impact': 285687,\n",
       " 'does impact windows': 132690,\n",
       " 'impact windows server': 202458,\n",
       " 'windows server oss': 461632,\n",
       " 'server oss linux': 373065,\n",
       " 'oss linux deployments': 288424,\n",
       " 'linux deployments permissions': 241931,\n",
       " 'deployments permissions inherited': 118151,\n",
       " 'permissions inherited root': 304704,\n",
       " 'inherited root directory': 210441,\n",
       " 'root directory authorized': 356843,\n",
       " 'directory authorized users': 125290,\n",
       " 'authorized users modify': 44837,\n",
       " 'users modify permission': 434697,\n",
       " 'modify permission esm': 267002,\n",
       " 'permission esm folders': 304255,\n",
       " 'esm folders allows': 147862,\n",
       " 'folders allows low': 172688,\n",
       " 'allows low privilege': 22576,\n",
       " 'low privilege account': 248622,\n",
       " 'privilege account modify': 322026,\n",
       " 'account modify files': 6978,\n",
       " 'modify files located': 266899,\n",
       " 'files located directories': 167874,\n",
       " 'located directories executable': 245017,\n",
       " 'directories executable renamed': 125129,\n",
       " 'executable renamed replaced': 150628,\n",
       " 'renamed replaced malicious': 345779,\n",
       " 'replaced malicious file': 346326,\n",
       " 'malicious file connect': 251991,\n",
       " 'file connect bad': 163930,\n",
       " 'connect bad actor': 88575,\n",
       " 'bad actor providing': 47000,\n",
       " 'actor providing level': 9345,\n",
       " 'providing level privileges': 331103,\n",
       " 'level privileges low': 237357,\n",
       " 'privileges low privileged': 323237,\n",
       " 'low privileged user': 248644,\n",
       " 'privileged user able': 322676,\n",
       " 'user able restart': 429622,\n",
       " 'able restart service': 2250,\n",
       " 'restart service restart': 351923,\n",
       " 'service restart trigger': 375994,\n",
       " 'restart trigger execution': 351948,\n",
       " 'trigger execution malicious': 415478,\n",
       " 'execution malicious file': 152321,\n",
       " 'malicious file affects': 251986,\n",
       " 'file affects exacq': 163593,\n",
       " 'affects exacq technologies': 16778,\n",
       " 'exacq technologies exacqvision': 149306,\n",
       " 'technologies exacqvision enterprise': 406630,\n",
       " 'manager esm prior': 254355,\n",
       " 'prior versions does': 321529,\n",
       " 'versions does affect': 443263,\n",
       " 'does affect exacq': 132412,\n",
       " 'affect exacq technologies': 15271,\n",
       " 'asusgio': 35088,\n",
       " 'asus': 35032,\n",
       " 'aura': 42150,\n",
       " 'sync': 403130,\n",
       " 'earlier': 137146,\n",
       " 'exposes': 158353,\n",
       " 'functionality': 179609,\n",
       " 'read': 336412,\n",
       " 'machine': 249581,\n",
       " 'registers': 342123,\n",
       " 'msrs': 269896,\n",
       " 'leveraged': 237565,\n",
       " 'execute': 150711,\n",
       " 'arbitrary': 30727,\n",
       " 'ring': 355850,\n",
       " 'code': 76259,\n",
       " 'asusgio low': 35089,\n",
       " 'low level': 248597,\n",
       " 'level driver': 237257,\n",
       " 'driver asus': 135342,\n",
       " 'asus aura': 35042,\n",
       " 'aura sync': 42164,\n",
       " 'sync earlier': 403137,\n",
       " 'earlier exposes': 137553,\n",
       " 'exposes functionality': 158380,\n",
       " 'functionality read': 179897,\n",
       " 'read write': 337800,\n",
       " 'write machine': 464524,\n",
       " 'machine specific': 249732,\n",
       " 'specific registers': 389872,\n",
       " 'registers msrs': 342138,\n",
       " 'msrs leveraged': 269897,\n",
       " 'leveraged execute': 237588,\n",
       " 'execute arbitrary': 150740,\n",
       " 'arbitrary ring': 31810,\n",
       " 'ring code': 355853,\n",
       " 'asusgio low level': 35090,\n",
       " 'low level driver': 248600,\n",
       " 'level driver asus': 237258,\n",
       " 'driver asus aura': 135343,\n",
       " 'asus aura sync': 35043,\n",
       " 'aura sync earlier': 42165,\n",
       " 'sync earlier exposes': 403139,\n",
       " 'earlier exposes functionality': 137554,\n",
       " 'exposes functionality read': 158382,\n",
       " 'functionality read write': 179898,\n",
       " 'read write machine': 337831,\n",
       " 'write machine specific': 464525,\n",
       " 'machine specific registers': 249733,\n",
       " 'specific registers msrs': 389874,\n",
       " 'registers msrs leveraged': 342139,\n",
       " 'msrs leveraged execute': 269898,\n",
       " 'leveraged execute arbitrary': 237589,\n",
       " 'execute arbitrary ring': 150770,\n",
       " 'arbitrary ring code': 31811,\n",
       " 'oracle': 287057,\n",
       " 'virtualbox': 446848,\n",
       " 'component': 83131,\n",
       " 'virtualization': 446872,\n",
       " 'subcomponent': 398241,\n",
       " 'core': 97409,\n",
       " 'supported': 401550,\n",
       " 'easily': 138182,\n",
       " 'exploitable': 156732,\n",
       " 'unauthenticated': 419057,\n",
       " 'logon': 247369,\n",
       " 'infrastructure': 210224,\n",
       " 'executes': 151597,\n",
       " 'compromise': 84143,\n",
       " 'attacks': 40761,\n",
       " 'require': 349347,\n",
       " 'human': 197635,\n",
       " 'person': 305295,\n",
       " 'significantly': 382303,\n",
       " 'additional': 10412,\n",
       " 'products': 326531,\n",
       " 'takeover': 404893,\n",
       " 'cvss': 108834,\n",
       " 'base': 47467,\n",
       " 'score': 363499,\n",
       " 'confidentiality': 85987,\n",
       " 'integrity': 217113,\n",
       " 'availability': 45443,\n",
       " 'vector': 441655,\n",
       " 'vulnerability oracle': 452829,\n",
       " 'oracle virtualbox': 287382,\n",
       " 'virtualbox component': 446853,\n",
       " 'component oracle': 83604,\n",
       " 'oracle virtualization': 287391,\n",
       " 'virtualization subcomponent': 446893,\n",
       " 'subcomponent core': 398323,\n",
       " 'core supported': 97840,\n",
       " 'supported affected': 401551,\n",
       " 'affected prior': 16138,\n",
       " 'prior easily': 320557,\n",
       " 'easily exploitable': 138212,\n",
       " 'exploitable vulnerability': 157171,\n",
       " 'vulnerability allows': 449213,\n",
       " 'allows unauthenticated': 22965,\n",
       " 'unauthenticated attacker': 419089,\n",
       " 'attacker logon': 38406,\n",
       " 'logon infrastructure': 247380,\n",
       " 'infrastructure oracle': 210285,\n",
       " 'virtualbox executes': 446857,\n",
       " 'executes compromise': 151619,\n",
       " 'compromise oracle': 84260,\n",
       " 'virtualbox successful': 446859,\n",
       " 'successful attacks': 399919,\n",
       " 'attacks require': 41079,\n",
       " 'require human': 349408,\n",
       " 'human interaction': 197638,\n",
       " 'interaction person': 218019,\n",
       " 'person attacker': 305296,\n",
       " 'attacker vulnerability': 39672,\n",
       " 'virtualbox attacks': 446851,\n",
       " 'attacks significantly': 41116,\n",
       " 'significantly impact': 382304,\n",
       " 'impact additional': 202036,\n",
       " 'additional products': 10519,\n",
       " 'products successful': 326832,\n",
       " 'attacks vulnerability': 41214,\n",
       " 'vulnerability result': 453508,\n",
       " 'result takeover': 353494,\n",
       " 'takeover oracle': 404929,\n",
       " 'virtualbox cvss': 446855,\n",
       " 'cvss base': 108841,\n",
       " 'base score': 47544,\n",
       " 'score confidentiality': 363510,\n",
       " 'confidentiality integrity': 86007,\n",
       " 'integrity availability': 217129,\n",
       " 'availability impacts': 45483,\n",
       " 'impacts cvss': 202559,\n",
       " 'cvss vector': 108857,\n",
       " 'vector cvss': 441701,\n",
       " 'vulnerability oracle virtualbox': 452902,\n",
       " 'oracle virtualbox component': 287385,\n",
       " 'virtualbox component oracle': 446854,\n",
       " 'component oracle virtualization': 83630,\n",
       " 'oracle virtualization subcomponent': 287392,\n",
       " 'virtualization subcomponent core': 446894,\n",
       " 'subcomponent core supported': 398327,\n",
       " 'core supported affected': 97841,\n",
       " 'supported affected prior': 401555,\n",
       " 'affected prior easily': 16141,\n",
       " 'prior easily exploitable': 320558,\n",
       " 'easily exploitable vulnerability': 138215,\n",
       " 'exploitable vulnerability allows': 157172,\n",
       " 'vulnerability allows unauthenticated': 449238,\n",
       " 'allows unauthenticated attacker': 22966,\n",
       " 'unauthenticated attacker logon': 419132,\n",
       " 'attacker logon infrastructure': 38407,\n",
       " 'logon infrastructure oracle': 247385,\n",
       " 'infrastructure oracle virtualbox': 210293,\n",
       " 'oracle virtualbox executes': 287387,\n",
       " 'virtualbox executes compromise': 446858,\n",
       " 'executes compromise oracle': 151624,\n",
       " 'compromise oracle virtualbox': 84333,\n",
       " 'oracle virtualbox successful': 287388,\n",
       " 'virtualbox successful attacks': 446860,\n",
       " 'successful attacks require': 399921,\n",
       " 'attacks require human': 41080,\n",
       " 'require human interaction': 349409,\n",
       " 'human interaction person': 197639,\n",
       " 'interaction person attacker': 218020,\n",
       " 'person attacker vulnerability': 305298,\n",
       " 'attacker vulnerability oracle': 39685,\n",
       " 'oracle virtualbox attacks': 287384,\n",
       " 'virtualbox attacks significantly': 446852,\n",
       " 'attacks significantly impact': 41117,\n",
       " 'significantly impact additional': 382305,\n",
       " 'impact additional products': 202037,\n",
       " 'additional products successful': 10520,\n",
       " 'products successful attacks': 326833,\n",
       " 'successful attacks vulnerability': 399922,\n",
       " 'attacks vulnerability result': 41228,\n",
       " 'vulnerability result takeover': 453518,\n",
       " 'result takeover oracle': 353500,\n",
       " 'takeover oracle virtualbox': 404944,\n",
       " 'oracle virtualbox cvss': 287386,\n",
       " 'virtualbox cvss base': 446856,\n",
       " 'cvss base score': 108842,\n",
       " 'base score confidentiality': 47548,\n",
       " 'score confidentiality integrity': 363513,\n",
       " 'confidentiality integrity availability': 86014,\n",
       " 'integrity availability impacts': 217137,\n",
       " 'availability impacts cvss': 45484,\n",
       " 'impacts cvss vector': 202560,\n",
       " 'cvss vector cvss': 108858,\n",
       " 'supervisor': 400975,\n",
       " 'avaya': 45851,\n",
       " 'management': 253378,\n",
       " 'administrative': 13449,\n",
       " 'extract': 159797,\n",
       " 'sensitive': 369807,\n",
       " 'information': 208745,\n",
       " 'connecting': 88954,\n",
       " 'cms': 75665,\n",
       " 'host': 193867,\n",
       " 'include': 205556,\n",
       " 'vulnerability supervisor': 454034,\n",
       " 'supervisor component': 400980,\n",
       " 'component avaya': 83223,\n",
       " 'avaya management': 45862,\n",
       " 'management allows': 253422,\n",
       " 'allows local': 22545,\n",
       " 'local administrative': 244118,\n",
       " 'administrative user': 13644,\n",
       " 'user extract': 431007,\n",
       " 'extract sensitive': 159861,\n",
       " 'sensitive information': 369954,\n",
       " 'information users': 210077,\n",
       " 'users connecting': 434234,\n",
       " 'connecting remote': 89011,\n",
       " 'remote cms': 344833,\n",
       " 'cms host': 75785,\n",
       " 'host affected': 193880,\n",
       " 'affected versions': 16499,\n",
       " 'versions cms': 443113,\n",
       " 'cms supervisor': 75917,\n",
       " 'supervisor include': 400987,\n",
       " 'vulnerability supervisor component': 454035,\n",
       " 'supervisor component avaya': 400981,\n",
       " 'component avaya management': 83226,\n",
       " 'avaya management allows': 45863,\n",
       " 'management allows local': 253428,\n",
       " 'allows local administrative': 22546,\n",
       " 'local administrative user': 244121,\n",
       " 'administrative user extract': 13657,\n",
       " 'user extract sensitive': 431008,\n",
       " 'extract sensitive information': 159863,\n",
       " 'sensitive information users': 370139,\n",
       " 'information users connecting': 210080,\n",
       " 'users connecting remote': 434235,\n",
       " 'connecting remote cms': 89012,\n",
       " 'remote cms host': 344834,\n",
       " 'cms host affected': 75786,\n",
       " 'host affected versions': 193884,\n",
       " 'affected versions cms': 16507,\n",
       " 'versions cms supervisor': 443114,\n",
       " 'cms supervisor include': 75918,\n",
       " 'configuration': 86371,\n",
       " 'hardware': 190155,\n",
       " 'access': 3011,\n",
       " 'intel': 217253,\n",
       " 'quickassist': 334560,\n",
       " 'technology': 406654,\n",
       " 'enable': 142231,\n",
       " 'improper configuration': 204717,\n",
       " 'configuration hardware': 86780,\n",
       " 'hardware access': 190163,\n",
       " 'access intel': 4311,\n",
       " 'intel quickassist': 217380,\n",
       " 'quickassist technology': 334561,\n",
       " 'technology linux': 406684,\n",
       " 'linux versions': 242257,\n",
       " 'versions allow': 442881,\n",
       " 'authenticated user': 42839,\n",
       " 'user potentially': 432226,\n",
       " 'potentially enable': 317401,\n",
       " 'enable denial': 142272,\n",
       " 'service local': 375537,\n",
       " 'local access': 244070,\n",
       " 'improper configuration hardware': 204721,\n",
       " 'configuration hardware access': 86781,\n",
       " 'hardware access intel': 190164,\n",
       " 'access intel quickassist': 4312,\n",
       " 'intel quickassist technology': 217381,\n",
       " 'quickassist technology linux': 334562,\n",
       " 'technology linux versions': 406686,\n",
       " 'linux versions allow': 242258,\n",
       " 'versions allow authenticated': 442885,\n",
       " 'allow authenticated user': 20364,\n",
       " 'authenticated user potentially': 42929,\n",
       " 'user potentially enable': 432234,\n",
       " 'potentially enable denial': 317402,\n",
       " 'enable denial service': 142273,\n",
       " 'denial service local': 117414,\n",
       " 'service local access': 375538,\n",
       " 'handling': 188828,\n",
       " 'vendor': 441949,\n",
       " 'command': 79850,\n",
       " 'potential': 317060,\n",
       " 'lack': 232351,\n",
       " 'received': 339318,\n",
       " 'snapdragon': 385939,\n",
       " 'auto': 44886,\n",
       " 'consumer': 90711,\n",
       " 'electronics': 140456,\n",
       " 'connectivity': 89615,\n",
       " 'iot': 221591,\n",
       " 'industrial': 208287,\n",
       " 'mobile': 265265,\n",
       " 'voice': 447755,\n",
       " 'music': 270814,\n",
       " 'mdm9607': 257046,\n",
       " 'mdm9640': 257090,\n",
       " 'msm8996au': 269790,\n",
       " 'qca6174a': 333082,\n",
       " 'qca6574au': 333099,\n",
       " 'qca9377': 333140,\n",
       " 'qca9379': 333159,\n",
       " 'qcs405': 333266,\n",
       " 'qcs605': 333273,\n",
       " 'sdm630': 365577,\n",
       " 'sdm660': 365596,\n",
       " 'sdx24': 365741,\n",
       " 'handling vendor': 189640,\n",
       " 'vendor command': 441964,\n",
       " 'command exists': 80119,\n",
       " 'exists potential': 154868,\n",
       " 'potential buffer': 317089,\n",
       " 'overflow lack': 289883,\n",
       " 'lack input': 232472,\n",
       " 'validation data': 438916,\n",
       " 'data buffer': 110097,\n",
       " 'buffer received': 56186,\n",
       " 'received snapdragon': 339462,\n",
       " 'snapdragon auto': 385940,\n",
       " 'auto snapdragon': 44930,\n",
       " 'snapdragon consumer': 385949,\n",
       " 'consumer electronics': 90721,\n",
       " 'electronics connectivity': 140461,\n",
       " 'connectivity snapdragon': 89664,\n",
       " 'consumer iot': 90729,\n",
       " 'iot snapdragon': 221617,\n",
       " 'snapdragon industrial': 385952,\n",
       " 'industrial iot': 208303,\n",
       " 'snapdragon mobile': 385956,\n",
       " 'mobile snapdragon': 265390,\n",
       " 'snapdragon voice': 385968,\n",
       " 'voice music': 447764,\n",
       " 'music mdm9607': 270830,\n",
       " 'mdm9607 mdm9640': 257056,\n",
       " 'mdm9640 msm8996au': 257101,\n",
       " 'msm8996au qca6174a': 269795,\n",
       " 'qca6174a qca6574au': 333087,\n",
       " 'qca6574au qca9377': 333105,\n",
       " 'qca9377 qca9379': 333143,\n",
       " 'qca9379 qcs405': 333169,\n",
       " 'qcs405 qcs605': 333267,\n",
       " 'qcs605 sdm630': 333285,\n",
       " 'sdm630 sdm660': 365582,\n",
       " 'sdm660 sdx24': 365604,\n",
       " 'handling vendor command': 189641,\n",
       " 'vendor command exists': 441965,\n",
       " 'command exists potential': 80120,\n",
       " 'exists potential buffer': 154869,\n",
       " 'potential buffer overflow': 317091,\n",
       " 'buffer overflow lack': 55750,\n",
       " 'overflow lack input': 289884,\n",
       " 'lack input validation': 232475,\n",
       " 'input validation data': 213524,\n",
       " 'validation data buffer': 438917,\n",
       " 'data buffer received': 110103,\n",
       " 'buffer received snapdragon': 56187,\n",
       " 'received snapdragon auto': 339463,\n",
       " 'snapdragon auto snapdragon': 385941,\n",
       " 'auto snapdragon consumer': 44933,\n",
       " 'snapdragon consumer electronics': 385950,\n",
       " 'consumer electronics connectivity': 90722,\n",
       " 'electronics connectivity snapdragon': 140462,\n",
       " 'connectivity snapdragon consumer': 89665,\n",
       " 'snapdragon consumer iot': 385951,\n",
       " 'consumer iot snapdragon': 90730,\n",
       " 'iot snapdragon industrial': 221618,\n",
       " 'snapdragon industrial iot': 385953,\n",
       " 'industrial iot snapdragon': 208304,\n",
       " 'iot snapdragon mobile': 221620,\n",
       " 'snapdragon mobile snapdragon': 385965,\n",
       " 'mobile snapdragon voice': 265391,\n",
       " 'snapdragon voice music': 385969,\n",
       " 'voice music mdm9607': 447767,\n",
       " 'music mdm9607 mdm9640': 270831,\n",
       " 'mdm9607 mdm9640 msm8996au': 257059,\n",
       " 'mdm9640 msm8996au qca6174a': 257102,\n",
       " 'msm8996au qca6174a qca6574au': 269798,\n",
       " 'qca6174a qca6574au qca9377': 333090,\n",
       " 'qca6574au qca9377 qca9379': 333106,\n",
       " 'qca9377 qca9379 qcs405': 333147,\n",
       " 'qca9379 qcs405 qcs605': 333170,\n",
       " 'qcs405 qcs605 sdm630': 333271,\n",
       " 'qcs605 sdm630 sdm660': 333286,\n",
       " 'sdm630 sdm660 sdx24': 365584,\n",
       " 'libreadstat': 239578,\n",
       " 'wizardmac': 462387,\n",
       " 'readstat': 338611,\n",
       " 'unterminated': 422672,\n",
       " 'string': 397113,\n",
       " 'libreadstat wizardmac': 239582,\n",
       " 'wizardmac readstat': 462388,\n",
       " 'readstat heap': 338612,\n",
       " 'buffer read': 56016,\n",
       " 'read unterminated': 337692,\n",
       " 'unterminated string': 422673,\n",
       " 'libreadstat wizardmac readstat': 239583,\n",
       " 'wizardmac readstat heap': 462389,\n",
       " 'readstat heap based': 338613,\n",
       " 'based buffer read': 47753,\n",
       " 'buffer read unterminated': 56172,\n",
       " 'read unterminated string': 337693,\n",
       " 'probe': 323879,\n",
       " 'request': 347247,\n",
       " 'indication': 208191,\n",
       " 'lim_send_sme_probe_req_ind': 240602,\n",
       " 'releases': 343784,\n",
       " 'caf': 59425,\n",
       " 'msm': 269748,\n",
       " 'firefox': 169814,\n",
       " 'qrd': 333748,\n",
       " 'using': 435763,\n",
       " 'occur': 281502,\n",
       " 'sending probe': 369510,\n",
       " 'probe request': 323898,\n",
       " 'request indication': 347845,\n",
       " 'indication lim_send_sme_probe_req_ind': 208202,\n",
       " 'lim_send_sme_probe_req_ind android': 240603,\n",
       " 'android releases': 24525,\n",
       " 'releases caf': 343816,\n",
       " 'caf android': 59426,\n",
       " 'android msm': 24464,\n",
       " 'msm firefox': 269749,\n",
       " 'firefox msm': 169865,\n",
       " 'msm qrd': 269753,\n",
       " 'qrd android': 333749,\n",
       " 'android using': 24584,\n",
       " 'using linux': 436465,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Items in vocabulary\n",
    "# vectorizer and pipeline are defined here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.svm import LinearSVC\n",
    "unwanted_words = ['issue','defect','bug','fault','flaw','mistake','error','version','system','because','before','disputed']\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "stop_words = stop_words.union(unwanted_words)\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 3), token_pattern=r'(?u)\\b\\w*[a-zA-Z]{3,}\\w*\\b')\n",
    "pipe = Pipeline([('vect', vectorizer), ('cls', LinearSVC())])\n",
    "pipe.fit(cvss3_texts[0]['text'], cvss3_texts[0]['label'])\n",
    "vectors = vectorizer.transform(cvss3_texts[0]['text'])\n",
    "print(\"Vectors shape:\" + str(vectors.shape))\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifier hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:559: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0.9579857757485293\n",
      "0:{'cls__dual': True, 'cls__loss': 'squared_hinge', 'cls__max_iter': 1000, 'cls__multi_class': 'ovr'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:559: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0.9210467385393006\n",
      "1:{'cls__dual': True, 'cls__loss': 'squared_hinge', 'cls__max_iter': 1000, 'cls__multi_class': 'ovr'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:559: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:0.9225113353212696\n",
      "2:{'cls__dual': True, 'cls__loss': 'squared_hinge', 'cls__max_iter': 1000, 'cls__multi_class': 'ovr'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:559: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3:0.9051317967655673\n",
      "3:{'cls__dual': True, 'cls__loss': 'squared_hinge', 'cls__max_iter': 1000, 'cls__multi_class': 'ovr'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:559: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# Takes hours with the full dataset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#hyperparameters\n",
    "parameters = {'cls__loss': ('hinge', 'squared_hinge'),#default: squared_hinge\n",
    "              'cls__dual': (True, False),#default: True\n",
    "              'cls__multi_class': ('ovr', 'crammer_singer'),#default: ovr\n",
    "              'cls__max_iter': (1000, 2000),#default: 1000\n",
    "             }\n",
    "gs = GridSearchCV(pipe, parameters, scoring='f1_micro', cv=10, error_score=np.nan)\n",
    "\n",
    "for i in range(6):# 6 classes on cvss2 metrics\n",
    "    gs = gs.fit(cvss2_texts[i]['text'], cvss2_texts[i]['label'])\n",
    "    print(str(i)+':'+str(gs.best_score_))\n",
    "    print(str(i)+':'+str(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):# 8 classes on cvss3 metrics\n",
    "    gs = gs.fit(cvss3_texts[i]['text'], cvss3_texts[i]['label'])\n",
    "    print(str(i)+':'+str(gs.best_score_))\n",
    "    print(str(i)+':'+str(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test predicting CVSS of a security related issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "reports = pd.read_excel('data/sec_issues_edit.xlsx')\n",
    "reports = reports.loc[(reports['security']==1)]\n",
    "reports['security'] = reports['security'].values.astype(bool)\n",
    "reports['report'] = reports['report'].values.astype(str)\n",
    "i = random.randint(0, len(reports)-1)\n",
    "random_report = reports.iloc[i]['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue 20233 : Crash potentially due to resource exhaustion 1 person starred this issue and may be notified of changes.   &nbsp;   sg.develop    MustLive sent a report on security@google.com which is included later. A simplified PoC by Michal is: perl -e '{print &quot;&lt;script&gt;location.hash='\\''&quot; &quot;A&quot;x20000000 &quot;'\\'';&lt;/script&gt;&quot;}' &gt;testme.html ...and it does not seem to be doing much  other than bogging down the UI by the virtue of dumping 20 megs into the URL bar. However  it did crash my Dev channel Chrome when using this PoC and accessing other tabs during the load. http://www.corp.google.com/~sumitg/no_crawl/chrome/mustlive- locationdos.html MustLive report: &quot;I want to warn you about Denial of Service vulnerability in Google Chrome. At the end of December DoS vulnerability in Mozilla Firefox 3.0.5 was found by Jeremy Brown ( http://websecurity.com.ua/2755/ ). After I checked at 23.12.2008 this vulnerability in different browsers  I found that this Denial of Service vulnerability also exists in Chrome 1.0.154.48. DoS: Original exploit ( http://www.milw0rm.com/exploits/7554 ). Use Google's cache because milw0rm.com is not working now (http://209.85.129.132/search? q=cache:aE09aeFDddMJ:www.milw0rm.com/exploits/7554+ http://www.milw0rm.com/e xploits/7554&amp;cd=1&amp;ct=clnk). With html file generated by this exploit in all affected browsers there is consuming of CPU resources (and some consuming of RAM resources  besides in those browsers  where there is no freeze  after closing of tab with exploit the memory is not released  so large amount of memory stays in use until closing of the browser). In Chrome 1.0.154.48 and previous versions the exploit leads to CPU Overload. But if to open empty tab and to close tab with the exploit  then on empty tab the browser can take 100% of CPU and freezes. Vulnerable version is Google Chrome 1.0.154.48 and previous versions (and potentially next versions). Attend to security of all of yours web sites  web software  browsers and to security-audit. I mentioned about this vulnerability at my site ( http://websecurity.com.ua/3424/). &quot; \n",
      "CVSS2: AV:N/AC:M/Au:N/C:N/I:N/A:C = 7.1\n",
      "CVSS3: AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H = 6.5\n"
     ]
    }
   ],
   "source": [
    "from cvsslib import cvss2, cvss3, calculate_vector\n",
    "\n",
    "print(random_report)\n",
    "\n",
    "report_metrics = []\n",
    "for i in range(6):# 6 labels on cvss2 metrics\n",
    "    pipe.fit(cvss2_texts[i]['text'], cvss2_texts[i]['label'])\n",
    "    predicted = pipe.predict([random_report])\n",
    "    report_metrics.append(predicted)\n",
    "\n",
    "vector = ''\n",
    "for m in report_metrics:\n",
    "    vector = vector + str(m[0].replace('/','')) + '/'\n",
    "vector = vector[0:len(vector)-1]\n",
    "score = calculate_vector(vector, cvss2)\n",
    "print('CVSS2: ' + vector + ' = ' + str(score[0]))\n",
    "\n",
    "report_metrics = []\n",
    "for i in range(8):# 8 classes on cvss3 metrics\n",
    "    pipe.fit(cvss3_texts[i]['text'], cvss3_texts[i]['label'])\n",
    "    predicted = pipe.predict([random_report])\n",
    "    report_metrics.append(predicted)\n",
    "\n",
    "vector = ''\n",
    "for m in report_metrics:\n",
    "    vector = vector + str(m[0].replace('/','')) + '/'\n",
    "vector = vector[0:len(vector)-1]\n",
    "score = calculate_vector(vector, cvss3)\n",
    "print('CVSS3: ' + vector + ' = ' + str(score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find optimal dataset size to fit the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: 0.6\n",
      "200: 0.6599999999999999\n",
      "500: 0.6623999999999999\n",
      "1000: 0.6896\n",
      "2000: 0.7132\n",
      "3000: 0.7358666666666667\n",
      "4000: 0.7449\n",
      "5000: 0.7556799999999999\n",
      "6000: 0.7619333333333332\n",
      "8000: 0.7847000000000002\n",
      "10000: 0.78076\n",
      "12000: 0.7917\n",
      "14000: 0.7964857142857142\n",
      "16000: 0.810225\n",
      "18000: 0.8053555555555555\n"
     ]
    }
   ],
   "source": [
    "from cvsslib import cvss2, cvss3, calculate_vector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sample_sizes = [100, 200, 500, 1000, 2000, 3000, 4000, 5000, 6000, 8000, 10000, 12000, 14000, 16000, 18000]\n",
    "\n",
    "for size in sample_sizes:\n",
    "    scores = []\n",
    "    for nfold in range(10):\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.drop(df[df[3] == ''].index)\n",
    "        df = df.drop(df[df[4] == ''].index)\n",
    "        df = df.drop([0,2,5,6,7], axis=1)\n",
    "        df = df.rename(index=str, columns={1: 'text', 3: 'vector'})\n",
    "        df = df.sample(n=size)\n",
    "        X_train, X_test, train_cvss_vectors, y_test = train_test_split(df['text'], df['vector'])\n",
    "\n",
    "        #fit and predict\n",
    "        pred = pd.DataFrame(X_test)\n",
    "        for i in range(6):# 6 classes on cvss2 metrics\n",
    "            vector = train_cvss_vectors.str.split('/').str.get(i)\n",
    "            pipe.fit(X_train, vector)\n",
    "            predicted = pipe.predict(X_test)\n",
    "            pred[i] = predicted\n",
    "\n",
    "        #calculate cvss2 scores\n",
    "        for index, value in pred.iterrows():\n",
    "            vector =''\n",
    "            for i in range(6):\n",
    "                vector = vector + value[i] + '/'\n",
    "            vector = vector[0:len(vector)-1]\n",
    "            score = calculate_vector(vector, cvss2)\n",
    "            pred.at[index, 'score'] = score[0]\n",
    "            pred.at[index, 'truth'] = df.loc[index][4]\n",
    "\n",
    "        pred.at[pred['score'] < 3.9, 'severity'] = 'low'\n",
    "        pred.at[pred['score'] >= 4.0, 'severity'] = 'medium'\n",
    "        pred.at[pred['score'] >= 7.0, 'severity'] = 'high'\n",
    "        pred.at[pred['score'] >= 9.0, 'severity'] = 'critical'\n",
    "\n",
    "        pred.at[pred['truth'] < 3.9, 'severity_truth'] = 'low'\n",
    "        pred.at[pred['truth'] >= 4.0, 'severity_truth'] = 'medium'\n",
    "        pred.at[pred['truth'] >= 7.0, 'severity_truth'] = 'high'\n",
    "        pred.at[pred['truth'] >= 9.0, 'severity_truth'] = 'critical'\n",
    "\n",
    "        scores.append(f1_score(y_true=pred['severity_truth'], y_pred=pred['severity'], average='micro'))\n",
    "\n",
    "    print(str(size) + ': ' + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: 0.44799999999999995\n",
      "200: 0.514\n",
      "500: 0.6048\n",
      "1000: 0.652\n",
      "2000: 0.6868\n",
      "3000: 0.7089333333333332\n",
      "4000: 0.7299999999999999\n",
      "5000: 0.7386400000000001\n",
      "6000: 0.7474666666666667\n",
      "8000: 0.7538\n",
      "10000: 0.7696799999999999\n",
      "12000: 0.7678333333333334\n",
      "14000: 0.7804\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-403-29c2c619ee5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m# 8 classes on cvss3 metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_cvss_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1032\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-395-5479b4350c3d>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0manalyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_analyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLemmaTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-395-5479b4350c3d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0manalyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_analyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLemmaTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[1;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m         \u001b[1;31m# 1. Apply rules once to the input to get y1, y2, y3, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1912\u001b[1;33m         \u001b[0mforms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_rules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mform\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;31m# 2. Return all that are in the database (and check the original too)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36mapply_rules\u001b[1;34m(forms)\u001b[0m\n\u001b[0;32m   1888\u001b[0m             return [\n\u001b[0;32m   1889\u001b[0m                 \u001b[0mform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1890\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1891\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubstitutions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1892\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1890\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1891\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubstitutions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1892\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1893\u001b[0m             ]\n\u001b[0;32m   1894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cvsslib import cvss2, cvss3, calculate_vector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sample_sizes = [100, 200, 500, 1000, 2000, 3000, 4000, 5000, 6000, 8000, 10000, 12000, 14000, 16000, 17900]\n",
    "\n",
    "for size in sample_sizes:\n",
    "    scores = []\n",
    "    for nfold in range(10):\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.drop(df[df[5] == ''].index)\n",
    "        df = df.drop(df[df[6] == ''].index)\n",
    "        df = df.drop([0,2,3,4,7], axis=1)\n",
    "        df = df.rename(index=str, columns={1: 'text', 5: 'vector'})\n",
    "        df = df.sample(n=size)\n",
    "        X_train, X_test, train_cvss_vectors, y_test = train_test_split(df['text'], df['vector'])\n",
    "\n",
    "        #fit and predict\n",
    "        pred = pd.DataFrame(X_test)\n",
    "        for i in range(8):# 8 classes on cvss3 metrics\n",
    "            vector = train_cvss_vectors.str.split('/').str.get(i+1)\n",
    "            pipe.fit(X_train, vector)\n",
    "            predicted = pipe.predict(X_test)\n",
    "            pred[i] = predicted\n",
    "\n",
    "        #calculate cvss3 scores\n",
    "        for index, value in pred.iterrows():\n",
    "            vector =''\n",
    "            for i in range(8):\n",
    "                vector = vector + value[i] + '/'\n",
    "            vector = vector[0:len(vector)-1]\n",
    "            score = calculate_vector(vector, cvss3)\n",
    "            pred.at[index, 'score'] = score[0]\n",
    "            pred.at[index, 'truth'] = df.loc[index][6]\n",
    "\n",
    "        pred.at[pred['score'] < 3.9, 'severity'] = 'low'\n",
    "        pred.at[pred['score'] >= 4.0, 'severity'] = 'medium'\n",
    "        pred.at[pred['score'] >= 7.0, 'severity'] = 'high'\n",
    "        pred.at[pred['score'] >= 9.0, 'severity'] = 'critical'\n",
    "        pred['severity'] = pred['severity'].values.astype(str)\n",
    "\n",
    "        pred.at[pred['truth'] < 3.9, 'severity_truth'] = 'low'\n",
    "        pred.at[pred['truth'] >= 4.0, 'severity_truth'] = 'medium'\n",
    "        pred.at[pred['truth'] >= 7.0, 'severity_truth'] = 'high'\n",
    "        pred.at[pred['truth'] >= 9.0, 'severity_truth'] = 'critical'\n",
    "        pred['severity_truth'] = pred['severity_truth'].values.astype(str)\n",
    "\n",
    "        scores.append(f1_score(y_true=pred['severity_truth'], y_pred=pred['severity'], average='micro'))\n",
    "\n",
    "    print(str(size) + ': ' + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test cvss classification against the nvd scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:23559 Testing data:7853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    critical       0.78      0.79      0.79       665\n",
      "        high       0.70      0.71      0.70      1324\n",
      "         low       0.79      0.75      0.77       880\n",
      "      medium       0.88      0.89      0.88      4984\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      7853\n",
      "   macro avg       0.79      0.79      0.79      7853\n",
      "weighted avg       0.83      0.83      0.83      7853\n",
      "\n",
      "[[ 528   66    1   70]\n",
      " [  59  938   16  311]\n",
      " [   1   18  662  199]\n",
      " [  86  322  162 4414]]\n"
     ]
    }
   ],
   "source": [
    "from cvsslib import cvss2, cvss3, calculate_vector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop(df[df[3] == ''].index)\n",
    "df = df.drop(df[df[4] == ''].index)\n",
    "df = df.drop([0,2,5,6,7], axis=1)\n",
    "df = df.rename(index=str, columns={1: 'text', 3: 'vector'})\n",
    "\n",
    "X_train, X_test, train_cvss_vectors, y_test = train_test_split(df['text'], df['vector'])\n",
    "print('Training data:' + str(len(X_train)) + ' Testing data:' + str(len(X_test)))\n",
    "\n",
    "#fit and predict\n",
    "pred = pd.DataFrame(X_test)\n",
    "for i in range(6):# 6 classes on cvss2 metrics\n",
    "    vector = train_cvss_vectors.str.split('/').str.get(i)\n",
    "    pipe.fit(X_train, vector)\n",
    "    predicted = pipe.predict(X_test)\n",
    "    pred[i] = predicted\n",
    "\n",
    "#calculate cvss2 scores\n",
    "for index, value in pred.iterrows():\n",
    "    vector =''\n",
    "    for i in range(6):\n",
    "        vector = vector + value[i] + '/'\n",
    "    vector = vector[0:len(vector)-1]\n",
    "    score = calculate_vector(vector, cvss2)\n",
    "    pred.at[index, 'score'] = score[0]\n",
    "    pred.at[index, 'truth'] = df.loc[index][4]\n",
    "\n",
    "pred.at[pred['score'] < 3.9, 'severity'] = 'low'\n",
    "pred.at[pred['score'] >= 4.0, 'severity'] = 'medium'\n",
    "pred.at[pred['score'] >= 7.0, 'severity'] = 'high'\n",
    "pred.at[pred['score'] >= 9.0, 'severity'] = 'critical'\n",
    "\n",
    "pred.at[pred['truth'] < 3.9, 'severity_truth'] = 'low'\n",
    "pred.at[pred['truth'] >= 4.0, 'severity_truth'] = 'medium'\n",
    "pred.at[pred['truth'] >= 7.0, 'severity_truth'] = 'high'\n",
    "pred.at[pred['truth'] >= 9.0, 'severity_truth'] = 'critical'\n",
    "\n",
    "print(classification_report(y_true=pred['severity_truth'], y_pred=pred['severity']))\n",
    "print(confusion_matrix(y_true=pred['severity_truth'], y_pred=pred['severity']))#, labels=['critical','high','medium','low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:21003 Testing data:7002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    critical       0.65      0.79      0.71      1046\n",
      "        high       0.80      0.85      0.82      3172\n",
      "         low       0.54      0.45      0.49        85\n",
      "      medium       0.91      0.78      0.84      2696\n",
      "         nan       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      7002\n",
      "   macro avg       0.58      0.57      0.57      7002\n",
      "weighted avg       0.82      0.81      0.81      7002\n",
      "\n",
      "[[ 829  204    1   12    0]\n",
      " [ 321 2688    7  156    0]\n",
      " [   6   11   38   30    0]\n",
      " [ 117  444   24 2111    0]\n",
      " [   0    3    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossi.jormakka\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df = df.drop(df[df[5] == ''].index)\n",
    "df = df.drop(df[df[6] == ''].index)\n",
    "df = df.drop([0,2,3,4,7], axis=1)\n",
    "df = df.rename(index=str, columns={1: 'text', 5: 'vector'})\n",
    "\n",
    "X_train, X_test, train_cvss_vectors, y_test = train_test_split(df['text'], df['vector'])\n",
    "print('Training data:' + str(len(X_train)) + ' Testing data:' + str(len(X_test)))\n",
    "\n",
    "#fit and predict\n",
    "pred = pd.DataFrame(X_test)\n",
    "for i in range(8):# 8 classes on cvss3 metrics\n",
    "    vector = train_cvss_vectors.str.split('/').str.get(i+1)#the first split is the CVSS version\n",
    "    pipe.fit(X_train, vector)\n",
    "    predicted = pipe.predict(X_test)\n",
    "    pred[i] = predicted\n",
    "\n",
    "#calculate cvss3 scores\n",
    "for index, value in pred.iterrows():\n",
    "    vector =''\n",
    "    for i in range(8):\n",
    "        vector = vector + value[i] + '/'\n",
    "    vector = vector[0:len(vector)-1]\n",
    "    score = calculate_vector(vector, cvss3)\n",
    "    pred.at[index, 'score'] = score[0]\n",
    "    pred.at[index, 'truth'] = df.loc[index][6]\n",
    "\n",
    "pred.at[pred['score'] < 3.9, 'severity'] = 'low'\n",
    "pred.at[pred['score'] >= 4.0, 'severity'] = 'medium'\n",
    "pred.at[pred['score'] >= 7.0, 'severity'] = 'high'\n",
    "pred.at[pred['score'] >= 9.0, 'severity'] = 'critical'\n",
    "pred['severity'] = pred['severity'].values.astype(str)\n",
    "\n",
    "pred.at[pred['truth'] < 3.9, 'severity_truth'] = 'low'\n",
    "pred.at[pred['truth'] >= 4.0, 'severity_truth'] = 'medium'\n",
    "pred.at[pred['truth'] >= 7.0, 'severity_truth'] = 'high'\n",
    "pred.at[pred['truth'] >= 9.0, 'severity_truth'] = 'critical'\n",
    "pred['severity_truth'] = pred['severity_truth'].values.astype(str)\n",
    "\n",
    "print(classification_report(y_true=pred['severity_truth'], y_pred=pred['severity']))\n",
    "print(confusion_matrix(y_true=pred['severity_truth'], y_pred=pred['severity']))#, labels=['critical','high','medium','low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check NVD vectors and score integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    critical       1.00      1.00      1.00      2636\n",
      "        high       1.00      1.00      1.00      5234\n",
      "         low       1.00      1.00      1.00      3500\n",
      "      medium       1.00      1.00      1.00     20042\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     31412\n",
      "   macro avg       1.00      1.00      1.00     31412\n",
      "weighted avg       1.00      1.00      1.00     31412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df = df.drop(df[df[3] == ''].index)\n",
    "df = df.drop(df[df[4] == ''].index)\n",
    "\n",
    "for index, value in df.iterrows():\n",
    "    score = calculate_vector(value[3], cvss2)\n",
    "    df.at[index, 'score'] = score[0]\n",
    "\n",
    "df.at[df['score'] < 3.9, 'severity'] = 'low'\n",
    "df.at[df['score'] >= 4.0, 'severity'] = 'medium'\n",
    "df.at[df['score'] >= 7.0, 'severity'] = 'high'\n",
    "df.at[df['score'] >= 9.0, 'severity'] = 'critical'\n",
    "df['severity'] = df['severity'].values.astype(str)\n",
    "\n",
    "df.at[df[4] < 3.9, 'severity_truth'] = 'low'\n",
    "df.at[df[4] >= 4.0, 'severity_truth'] = 'medium'\n",
    "df.at[df[4] >= 7.0, 'severity_truth'] = 'high'\n",
    "df.at[df[4] >= 9.0, 'severity_truth'] = 'critical'\n",
    "df['severity_truth'] = df['severity_truth'].values.astype(str)\n",
    "    \n",
    "print(classification_report(y_true=df['severity_truth'], y_pred=df['severity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CVSS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    critical       1.00      1.00      1.00      4082\n",
      "        high       1.00      1.00      1.00     12672\n",
      "         low       1.00      1.00      1.00       311\n",
      "      medium       1.00      1.00      1.00     10931\n",
      "         nan       1.00      1.00      1.00         9\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     28005\n",
      "   macro avg       1.00      1.00      1.00     28005\n",
      "weighted avg       1.00      1.00      1.00     28005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df = df.drop(df[df[5] == ''].index)\n",
    "df = df.drop(df[df[6] == ''].index)\n",
    "\n",
    "for index, value in df.iterrows():\n",
    "    score = calculate_vector(value[5], cvss3)\n",
    "    df.at[index, 'score'] = score[0]\n",
    "\n",
    "df.at[df['score'] < 3.9, 'severity'] = 'low'\n",
    "df.at[df['score'] >= 4.0, 'severity'] = 'medium'\n",
    "df.at[df['score'] >= 7.0, 'severity'] = 'high'\n",
    "df.at[df['score'] >= 9.0, 'severity'] = 'critical'\n",
    "df['severity'] = df['severity'].values.astype(str)\n",
    "\n",
    "df.at[df[6] < 3.9, 'severity_truth'] = 'low'\n",
    "df.at[df[6] >= 4.0, 'severity_truth'] = 'medium'\n",
    "df.at[df[6] >= 7.0, 'severity_truth'] = 'high'\n",
    "df.at[df[6] >= 9.0, 'severity_truth'] = 'critical'\n",
    "df['severity_truth'] = df['severity_truth'].values.astype(str)\n",
    "    \n",
    "print(classification_report(y_true=df['severity_truth'], y_pred=df['severity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
